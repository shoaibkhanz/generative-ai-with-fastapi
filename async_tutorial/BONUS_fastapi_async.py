"""
BONUS: FastAPI Async Deep Dive
================================

How async concepts apply to your FastAPI + AWS Bedrock application.

Author: Your AI Programming Instructor
Level: Advanced (Apply knowledge to real project)
"""

import asyncio
import time
from typing import List, Dict
import boto3
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel


def print_section(title: str):
    """Helper to print section headers"""
    print(f"\n{'=' * 70}")
    print(f"  {title}")
    print("=" * 70)


# =============================================================================
# PART 1: Why FastAPI Uses Async
# =============================================================================


def explain_fastapi_async():
    """
    Explains why FastAPI is built on async.
    """
    print_section("PART 1: Why FastAPI Uses Async")

    print("""
    üöÄ FastAPI's Async Architecture
    
    FastAPI is built on:
    1. Starlette (ASGI framework)
    2. Uvicorn (ASGI server with asyncio)
    3. Pydantic (data validation)
    
    Why Async?
    ‚úì Handle 1000+ concurrent requests on single process
    ‚úì Perfect for I/O-bound operations (APIs, databases)
    ‚úì Non-blocking during AWS Bedrock API calls
    ‚úì Low memory footprint
    ‚úì Excellent performance
    
    Your Current Stack:
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  Client Request                          ‚îÇ
    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
    ‚îÇ  FastAPI (async route handler)          ‚îÇ
    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
    ‚îÇ  boto3 bedrock.converse()               ‚îÇ
    ‚îÇ  (Currently BLOCKING! ‚ö†Ô∏è)                ‚îÇ
    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
    ‚îÇ  AWS Bedrock API                        ‚îÇ
    ‚îÇ  (Network I/O - could be async)         ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    
    Problem: boto3 is synchronous!
    Your async route handler blocks on boto3 calls.
    
    Solution: Use run_in_executor() or aioboto3
    """)


# =============================================================================
# PART 2: Your Current FastAPI App (Blocking Issue)
# =============================================================================


# Simulated bedrock client (your actual code uses boto3)
class MockBedrockClient:
    """Mock bedrock client that simulates blocking behavior"""

    def converse(self, modelId: str, messages: List, **kwargs) -> Dict:
        """This BLOCKS the event loop!"""
        print(f"  üî® BLOCKING call to {modelId}")
        time.sleep(1.0)  # Simulates network latency
        return {
            "output": {"message": {"content": [{"text": "Response"}]}},
            "usage": {"inputTokens": 10, "outputTokens": 20},
        }


app = FastAPI()
bedrock_client = MockBedrockClient()


# CURRENT VERSION: Blocks event loop!
@app.post("/chat-blocking")
async def chat_blocking(prompt: str):
    """
    ‚ö†Ô∏è PROBLEM: This blocks the event loop!

    Even though this is an async function, boto3.converse()
    is synchronous and will block for ~1 second.

    Impact:
    - Other requests must wait
    - Can't handle concurrent requests efficiently
    - Defeats the purpose of async FastAPI
    """
    response = bedrock_client.converse(  # ‚Üê BLOCKS HERE!
        modelId="anthropic.claude-3-5-sonnet-20241022-v2:0",
        messages=[{"role": "user", "content": [{"text": prompt}]}],
        inferenceConfig={"maxTokens": 1000, "temperature": 0.7},
    )
    return {"response": response["output"]["message"]["content"][0]["text"]}


async def demo_blocking_issue():
    """
    Demonstrates the blocking issue.
    """
    print_section("PART 2: The Blocking Issue")

    print("\nüìå Testing blocking endpoint with 3 concurrent requests:\n")

    # Simulate 3 concurrent requests
    import httpx

    async with httpx.AsyncClient(base_url="http://localhost:8000") as client:
        start = time.time()

        # These should be concurrent, but will block sequentially
        tasks = [
            client.post("/chat-blocking", json={"prompt": f"Request {i}"})
            for i in range(3)
        ]

        responses = await asyncio.gather(*tasks)
        elapsed = time.time() - start

        print(f"\n‚è±Ô∏è  Total time: {elapsed:.2f}s")
        print("‚ö†Ô∏è  Expected: ~1s (concurrent)")
        print("‚ùå  Got: ~3s (sequential blocking)")


# =============================================================================
# PART 3: Solution 1 - run_in_executor()
# =============================================================================


@app.post("/chat-executor")
async def chat_with_executor(prompt: str):
    """
    ‚úÖ SOLUTION 1: Use run_in_executor()

    This runs the blocking boto3 call in a thread pool,
    freeing up the event loop to handle other requests.
    """
    loop = asyncio.get_event_loop()

    # Run blocking operation in thread pool
    response = await loop.run_in_executor(
        None,  # Use default ThreadPoolExecutor
        lambda: bedrock_client.converse(
            modelId="anthropic.claude-3-5-sonnet-20241022-v2:0",
            messages=[{"role": "user", "content": [{"text": prompt}]}],
            inferenceConfig={"maxTokens": 1000, "temperature": 0.7},
        ),
    )

    return {"response": response["output"]["message"]["content"][0]["text"]}


def explain_executor_solution():
    """
    Explains the run_in_executor solution.
    """
    print_section("PART 3: Solution 1 - run_in_executor()")

    print("""
    ‚úÖ Using run_in_executor()
    
    What it does:
    1. Takes blocking function
    2. Runs it in a thread from ThreadPoolExecutor
    3. Returns awaitable Future
    4. Event loop free to handle other requests
    
    Code:
    ```python
    loop = asyncio.get_event_loop()
    response = await loop.run_in_executor(
        None,  # Default thread pool
        blocking_function,
        arg1, arg2
    )
    ```
    
    Pros:
    ‚úì Works with any blocking library (boto3, requests, etc.)
    ‚úì Easy to implement
    ‚úì No need to change library
    
    Cons:
    ‚ö†Ô∏è Still uses threads (memory overhead)
    ‚ö†Ô∏è Limited by thread pool size
    ‚ö†Ô∏è Not true async (but good enough!)
    
    Performance:
    - 3 requests: ~1s (concurrent) ‚úÖ
    - 100 requests: Still good
    - 1000+ requests: Thread pool becomes bottleneck
    """)


# =============================================================================
# PART 4: Solution 2 - aioboto3 (True Async)
# =============================================================================

"""
# Uncomment if aioboto3 is installed
import aioboto3

@app.post("/chat-async")
async def chat_fully_async(prompt: str):
    '''
    ‚úÖ SOLUTION 2: Use aioboto3 (True async boto3)
    
    This is truly async - no threads needed!
    '''
    session = aioboto3.Session()
    async with session.client("bedrock-runtime", region_name="us-west-2") as bedrock:
        response = await bedrock.converse(
            modelId="anthropic.claude-3-5-sonnet-20241022-v2:0",
            messages=[{"role": "user", "content": [{"text": prompt}]}],
            inferenceConfig={"maxTokens": 1000, "temperature": 0.7}
        )
        return {"response": response["output"]["message"]["content"][0]["text"]}
"""


def explain_aioboto3_solution():
    """
    Explains the aioboto3 solution.
    """
    print_section("PART 4: Solution 2 - aioboto3 (True Async)")

    print("""
    ‚úÖ Using aioboto3 (Async boto3)
    
    What it is:
    - Async wrapper around boto3
    - Uses aiohttp for HTTP calls
    - Truly non-blocking
    
    Installation:
    ```bash
    pip install aioboto3
    ```
    
    Code:
    ```python
    import aioboto3
    
    session = aioboto3.Session()
    async with session.client("bedrock-runtime") as bedrock:
        response = await bedrock.converse(...)
    ```
    
    Pros:
    ‚úì True async (no threads)
    ‚úì Maximum concurrency
    ‚úì Best performance
    ‚úì Low memory footprint
    
    Cons:
    ‚ö†Ô∏è Additional dependency
    ‚ö†Ô∏è Slightly different API
    
    Performance:
    - 3 requests: ~1s ‚úÖ
    - 100 requests: ~1s ‚úÖ  
    - 1000+ requests: ~2-3s ‚úÖ (Amazing!)
    """)


# =============================================================================
# PART 5: Comparison & Recommendations
# =============================================================================


def comparison_table():
    """
    Compares the different approaches.
    """
    print_section("PART 5: Comparison & Recommendations")

    print("""
    üìä COMPARISON TABLE
    
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  Approach      ‚îÇ  Complexity  ‚îÇ  Performance    ‚îÇ  Scalability ‚îÇ
    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
    ‚îÇ  Blocking      ‚îÇ  ‚≠ê Simple   ‚îÇ  ‚ùå Poor (3s)   ‚îÇ  ‚ùå Low      ‚îÇ
    ‚îÇ  (Current)     ‚îÇ              ‚îÇ                 ‚îÇ              ‚îÇ
    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
    ‚îÇ  Executor      ‚îÇ  ‚≠ê‚≠ê Easy   ‚îÇ  ‚úÖ Good (1s)   ‚îÇ  ‚≠ê‚≠ê‚≠ê Med  ‚îÇ
    ‚îÇ  (Threading)   ‚îÇ              ‚îÇ                 ‚îÇ              ‚îÇ
    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
    ‚îÇ  aioboto3      ‚îÇ  ‚≠ê‚≠ê‚≠ê Med  ‚îÇ  ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Best ‚îÇ  ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê   ‚îÇ
    ‚îÇ  (True async)  ‚îÇ              ‚îÇ                 ‚îÇ              ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    
    üéØ RECOMMENDATIONS
    
    For Your FastAPI + Bedrock App:
    
    1. SHORT TERM (Easiest):
       ‚úÖ Use run_in_executor()
       - Change: 3-5 lines of code
       - Works with existing boto3
       - Good enough for most cases
       - Handles 100s of concurrent requests
    
    2. LONG TERM (Best):
       ‚úÖ Switch to aioboto3
       - True async, best performance
       - Handles 1000s of concurrent requests
       - Future-proof
       - Minimal code changes
    
    3. PRODUCTION TIPS:
       ‚úì Use connection pooling
       ‚úì Set timeouts on all API calls
       ‚úì Implement retry logic
       ‚úì Add request rate limiting
       ‚úì Monitor event loop lag
       ‚úì Use background tasks for non-urgent work
    """)


# =============================================================================
# PART 6: FastAPI Async Best Practices
# =============================================================================


def fastapi_best_practices():
    """
    Best practices for async FastAPI.
    """
    print_section("PART 6: FastAPI Async Best Practices")

    print("""
    üèÜ FASTAPI ASYNC BEST PRACTICES
    
    1. Route Handlers:
       ‚úì Use 'async def' for I/O-bound endpoints
       ‚úì Use 'def' for CPU-bound (FastAPI runs in threadpool)
       
       ```python
       @app.get("/fast")
       async def io_bound():  # I/O operations
           data = await fetch_from_api()
           return data
       
       @app.get("/compute")
       def cpu_bound():  # Heavy computation
           result = complex_calculation()
           return result
       ```
    
    2. Dependencies:
       ‚úì Make dependencies async if they do I/O
       
       ```python
       async def get_db():
           # Async database connection
           async with database.session() as session:
               yield session
       
       @app.get("/data")
       async def get_data(db = Depends(get_db)):
           return await db.query(...)
       ```
    
    3. Background Tasks:
       ‚úì Use BackgroundTasks for non-urgent work
       
       ```python
       from fastapi import BackgroundTasks
       
       async def log_interaction(data):
           await save_to_db(data)
       
       @app.post("/chat")
       async def chat(bg_tasks: BackgroundTasks):
           response = await get_response()
           bg_tasks.add_task(log_interaction, response)
           return response  # Return immediately
       ```
    
    4. Startup/Shutdown Events:
       ‚úì Initialize connections at startup
       
       ```python
       @app.on_event("startup")
       async def startup():
           app.state.bedrock = await init_bedrock_client()
       
       @app.on_event("shutdown")
       async def shutdown():
           await app.state.bedrock.close()
       ```
    
    5. Error Handling:
       ‚úì Use timeouts
       ‚úì Handle exceptions properly
       
       ```python
       @app.post("/chat")
       async def chat(prompt: str):
           try:
               response = await asyncio.wait_for(
                   bedrock_call(prompt),
                   timeout=30.0
               )
               return response
           except asyncio.TimeoutError:
               raise HTTPException(504, "Request timeout")
           except Exception as e:
               raise HTTPException(500, str(e))
       ```
    
    6. Monitoring:
       ‚úì Track event loop lag
       ‚úì Monitor response times
       ‚úì Log slow requests
       
       ```python
       import time
       
       @app.middleware("http")
       async def log_requests(request, call_next):
           start = time.time()
           response = await call_next(request)
           duration = time.time() - start
           
           if duration > 1.0:
               logger.warning(f"Slow request: {duration:.2f}s")
           
           return response
       ```
    """)


# =============================================================================
# MAIN: Run All Demos
# =============================================================================


def main():
    """
    Main function to run all demonstrations.
    """
    print("\n" + "üéì" * 35)
    print("  BONUS: FASTAPI ASYNC DEEP DIVE")
    print("üéì" * 35)

    # Part 1: Why async
    explain_fastapi_async()
    input("\n‚è∏Ô∏è  Press Enter to continue...")

    # Part 3: Executor solution
    explain_executor_solution()
    input("\n‚è∏Ô∏è  Press Enter to continue...")

    # Part 4: aioboto3 solution
    explain_aioboto3_solution()
    input("\n‚è∏Ô∏è  Press Enter to continue...")

    # Part 5: Comparison
    comparison_table()
    input("\n‚è∏Ô∏è  Press Enter to continue...")

    # Part 6: Best practices
    fastapi_best_practices()

    print("\n" + "=" * 70)
    print("üéâ BONUS LESSON COMPLETE!")
    print("=" * 70)
    print("\nüìö Key Takeaways:")
    print("   1. FastAPI is built on async for high concurrency")
    print("   2. boto3 is blocking - use run_in_executor()")
    print("   3. aioboto3 offers true async boto3")
    print("   4. Use 'async def' for I/O-bound routes")
    print("   5. Use BackgroundTasks for non-urgent work")
    print("\nüöÄ Apply this to your FastAPI + Bedrock app!")
    print("   Update basics/basic_fastapi.py with run_in_executor()")


if __name__ == "__main__":
    main()
